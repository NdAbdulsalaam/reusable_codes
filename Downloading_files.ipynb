{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(\"image_predictions.tsv\"):\n",
    "    try:\n",
    "        url = \"https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\"\n",
    "        page = requests.get(url)\n",
    "        print('Connection sucessful')\n",
    "        with open('image_predictions.tsv', 'wb') as file:\n",
    "            file.write(page.content)\n",
    "            print('File saved successfully')\n",
    "    except OSError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to download\n",
      "Unable to download\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "try:\n",
    "    df_08 = pd.read_csv('data/all_alpha_08.csv')\n",
    "    df_18 = pd.read_csv('data/all_alpha_18.csv')\n",
    "    print(\"File available \\nFile loaded successfully.\")\n",
    "except IOError:\n",
    "    print(\"Trying to download\")\n",
    "    try:\n",
    "        from urllib.request import urlretrieve\n",
    "        urlretrieve('https://viewb5fd87e9.udacity-student-workspaces.com/edit/all_alpha_08.csv', 'data/all_alpha_08.csv')\n",
    "        urlretrieve('https://viewb5fd87e9.udacity-student-workspaces.com/edit/all_alpha_18.csv', 'data/all_alpha_18.csv')\n",
    "        print(\"Downloaded!\")\n",
    "        df_08 = pd.read_csv('data/all_alpha_08.csv')\n",
    "        df_18 = pd.read_csv('data/all_alpha_18.csv')\n",
    "        print(\"File loaded successfully.\")\n",
    "    except OSError:\n",
    "        print('Unable to download')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download tweets with API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tweepy\n",
    "#from tweepy import OAuthHandler\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n",
    "# These are hidden to comply with Twitter's API terms and conditions\n",
    "consumer_key = '5KgMKCsflSauz2pdgOHgis7cA'\n",
    "consumer_secret = 'zXHou4i4tAvOzzgnmFlznHERNwGzcu4TAoZwul8YOHvWwKeqt8'\n",
    "access_token = '1306337559082135557-H34iApBBuwsXw6MjYlV4YTdPayiqkT'\n",
    "access_secret = 'kJmO3NecAs9yZiquSETQa5kQvjokxfimtT7ZwgIfQiEi1'\n",
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAABiueAEAAAAAyDyqycBf7Qz7dK73PMHcDAtOL3k%3DhmEeVZoqTRmbJSTSPLGusJldqhvdQKtJgV9mi5rzhfVTFkCBB4'\n",
    "\n",
    "#auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# NOTE TO STUDENT WITH MOBILE VERIFICATION ISSUES:\n",
    "# df_1 is a DataFrame with the twitter_archive_enhanced.csv file. You may have to\n",
    "# change line 17 to match the name of your DataFrame with twitter_archive_enhanced.csv\n",
    "# NOTE TO REVIEWER: this student had mobile verification issues so the following\n",
    "# Twitter API code was sent to this student from a Udacity instructor\n",
    "# Tweet IDs for which to gather additional data via Twitter's API\n",
    "tweet_ids = df_archive.tweet_id.values\n",
    "len(tweet_ids)\n",
    "\n",
    "# Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "count = 0\n",
    "fails_dict = {}\n",
    "start = timer()\n",
    "# Save each tweet's returned JSON as a new line in a .txt file\n",
    "with open('tweet_json.txt', 'w') as outfile:\n",
    "    # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "    for tweet_id in tweet_ids:\n",
    "        count += 1\n",
    "        print(str(count) + \": \" + str(tweet_id))\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            print(\"Success\")\n",
    "            json.dump(tweet._json, outfile)\n",
    "            outfile.write('\\n')\n",
    "        except tweepy.TweepError as e:\n",
    "            print(\"Fail\")\n",
    "            fails_dict[tweet_id] = e\n",
    "            pass\n",
    "end = timer()\n",
    "print(end - start)\n",
    "print(fails_dict)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
